\svnid{$Id: parallel.tex 72876 2021-09-12 18:26:04Z mooiman $}

\chapter{Parallellization}

\section{Introduction}
\DFLOWFM{} can run parallel calculations and uses the Message Passing Interface standard (MPI) for that.

\section{Code dependencies on MPI}
MPI is now a requirement for \DFLOWFM{}, not directly, but via an implicit MPI-depency required by \texttt{deltares\_common}. Still, the \DFLOWFM{} code contains preprocessing directives to enable the MPI-specific code:
\begin{alltt}
#ifdef HAVE_MPI
 use mpi
#endif
\end{alltt}

\section{Partition mesh and MDU files in the command line}
\label{sec_partmeshmdu}
A partitioned model can be run interactively on Windows, for the purpose of debugging with Visual Studio. Running a model as a parallel calculation requires preparing and partitioning your model input files. Both the mesh and the MDU files need to be partitioned. See \cite{DFLOWFM_UM} for more details on how to implement the partitioning.

There are two types of partitioning the mesh: METIS and manually partition with a user-specified polygon. The command that uses METIS partitioner reads:
\begin{Verbatim}[frame=single, framesep=6pt]
> dflowfm-cli --partition:ndomains=n <meshfile> 
\end{Verbatim}
where \verb|ndomains=n| specifies that \verb|n| subdomains are to be generated. This command results in subdomain mesh files \file{example\_000j\_net.nc}, \verb|j=0,1,...,n-1|.
An advanced command, which enables more options, is:
\begin{Verbatim}[frame=single, framesep=6pt]
> dflowfm-cli --partition:ndomains=n[:method=0|1][:genpolygon=0|1][:contiguous=
0|1] <meshfile> 
\end{Verbatim}
where the partition method can be chosen via setting \verb|method=0| the Recursive Bisection apporach (default), and \verb|method=1| the K-Way approach. We refer to \cite{Kar11} for more details about these two approaches. 

Option \verb|genpolygon| is used to specify whether or not a partition polygon is generated. Such polygon file stands for the boundaries of subdomains, and can be used to generate subdomain cell coloring in the initialization stage of a parallel simulation.\footnote{METIS results in subdomain cell coloring information, i.e. cells that are in the same subdomain have the same color. This information is important in the initialization stage of a parallel run, where the old \DFLOWFM computes this information using a partition polygon which is generated by the partition command. This method could not be used for the 1D network where it is difficult to define such a polygon. The new development (default setting) is that no such polygon is generated or used anymore. The cell coloring information is written to partition mesh files, and then read for the parallel simulation. In this way, both 1D and 2D networks can be simulated.}By default, no such polygon file is generated (\verb|genpolygon=0|), and the subdomain cell coloring information are written into the partition mesh files. When \verb|genpolygon=1|, a polygon file will be generated and the cell coloring won't be written to the resulting mesh files.

Moreover, option \verb|contiguous| enforces the contiguous partition when specifying both \verb|contiguous=1| and \verb|method=1|. (Only the K-Way method enables the contiguous partition.) It is not switched on by default. Comparing to the previous command, this advanced command additionally generates a partition polygon file \file{example\_part.pol} when \verb|genpolygon=1| is specified. 

To manually partition a mesh, a user-specified polygon file \file{userpols.pol} has to be provided. The corresponding command reads:
\begin{Verbatim}[frame=single, framesep=6pt]
> dflowfm --partition <meshfile> <userpol.pol>
\end{Verbatim}
This generates files the same as before.

There is an efficient way to partition both the mesh and MDU files, by:
\begin{Verbatim}[frame=single, framesep=6pt]
> dflowfm-cli --partition:ndomains=n[:method=0|1][:genpolygon=0|1][:contiguous=0|1]
[:icgsolver=i] <mdu-file> 
\end{Verbatim}
This command reads the name of the mesh file from \verb|mdu-file|, and generates \verb|n| subdomain mesh files. Accordingly, it creates \verb|n| subdomain MDU files where the \verb|icgsolver| is set to \verb|i|. If the user specifies \verb|genpolygon=1|, then additionally a partition polygon file \verb|example_part.pol| is generated, and the resulting MDU files contains \verb|PartitionFile = example_part.pol|.

\section{Parallel runs and debugging on Windows}
Once the model input is complete, a parallel debugging session is started as follows:
\begin{enumerate}
\item \textbf{Start the MPI daemon.} This is a one-time operation. Open a DOS-box, make sure the Intel runtime programs are available and start the SMPD program in debug mode:\\
\begin{Verbatim}
$ call "%IFORT14_COMPILER%\bin\ipsxe-comp-vars.bat" intel64 vs2012
$ smpd.exe -d
\end{Verbatim}
\ \\
(Replace \verb|IFORT14| in case you've got a different Intel Fortran version.)
\item \textbf{Start the parallel model run.} In another DOS-box, where again the Intel runtime programs are available, use the mpiexec command to start the parallel run. Do this from inside the model directory where the MDU-files are located. Specify the full path to the \verb|dflowfm.exe| program which you will be debugging:
\\
\begin{Verbatim}
$ mpiexec.exe -localonly -np 3 D:\your_dfm_sourcecode\bin\x64\Debug\dflowfm.exe
     --autostartstop --pressakey yourmodel.mdu
\end{Verbatim}
\ \\
(Here \verb|localonly| specify that you are going to run on a local machine and \verb|-np 3| specifies the number of processes, specific for your simulation.)
Notice the use of the \verb|--pressakey| option. This will put the parallel processes on hold so that you first have the opportunity to attach the debugger in the following step. Also note that you may add the \verb|--nodisplay| option if you don't need the Interacter GUI during debugging.
\item \textbf{Attach the Visual Studio debugger to the parallel processes.} Make sure you are in the Debug configuration (and x64 platform in the above command, but Win32 is also possible). Click the menu item \menu{DEBUG $>$ Attach to Process\ldots} In the attach-dialog look for the \verb|dflowfm.exe| processes and select all of them that you have just launched in the previous step (use Ctrl-key + mouse click to select multiple processes).
\item \textbf{Start the actual debugging.} Prepare for debugging as you would do normally, e.g., placing breakpoints or watches. Start the actual run but returning to the mpiexec-DOS box and pressing the Enter-key once. All processess will then start running. Return to Visual Studio and start debugging.
\end{enumerate}


\section{Some related development}
\begin{itemize}
	\item When partition a mesh, the cell information (i.e. netcell\%nod and netcell\%lin in the code) of each subdomain is written to the subdomain mesh files, so that in the parallel run, the expensive step of finding cell information is skipped (i.e. skip subroutines findcells and find1dcells).  Moreover, if there is no cell information in the mesh file, the step of finding cells is automatically switched on. This also works in sequential run.
	\item In the command line, we can save net file with cell information, by option \verb|convertnetcells|.
\end{itemize}